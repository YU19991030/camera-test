from flask import Flask, request, jsonify, send_from_directory
from flask_cors import CORS
from flask_socketio import SocketIO, emit
from paddleocr import PaddleOCR
from pydub import AudioSegment
from io import BytesIO
import base64, io, os, numpy as np, cv2
from PIL import Image
import tempfile
from faster_whisper import WhisperModel
from sqlalchemy import create_engine, Column, Integer, Text, DateTime
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import sessionmaker
from datetime import datetime


app = Flask(__name__)
CORS(app)
socketio = SocketIO(app, cors_allowed_origins="*")

# PaddleOCR åˆå§‹åŒ–ï¼ˆç¹é«”ä¸­æ–‡ + è‡ªå‹•è½‰å‘ï¼‰
ocr = PaddleOCR(use_angle_cls=True, lang='ch')

# Whisper æ¨¡å‹åˆå§‹åŒ–
device = "cpu"
model = WhisperModel("base", device=device, compute_type="float32")
print(f"ğŸš€ faster-whisper ä½¿ç”¨è¨­å‚™ï¼š{device}")

last_sentences = []

# ğŸ“„ åœ–ç‰‡ OCR è¾¨è­˜ API
@app.route("/ocr", methods=["POST"])
def ocr_api():
    try:
        data = request.get_json()
        base64_str = data["image"].split(",")[1]
        image_data = base64.b64decode(base64_str)
        image = Image.open(BytesIO(image_data)).convert("RGB")
        img = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)

        result = ocr.ocr(img, cls=True)
        text = "\n".join([line[1][0] for box in result for line in box])

        print("ğŸ“„ è¾¨è­˜çµæœï¼š", text)
        return jsonify({"text": text})
    except Exception as e:
        print("âŒ è¾¨è­˜éŒ¯èª¤ï¼š", e)
        return jsonify({"text": "", "error": str(e)})

# ğŸ”Š Whisper èªéŸ³è¾¨è­˜ WebSocket æ¥å£
@socketio.on("start_recording")
def handle_start():
    print("ğŸ¬ é–‹å§‹éŒ„éŸ³")

@socketio.on("stop_recording")
def handle_stop():
    print("ğŸ›‘ åœæ­¢éŒ„éŸ³")

@socketio.on("audio")
def handle_audio(data):
    try:
        audio_bytes = BytesIO(data["audio"])
        audio = AudioSegment.from_file(audio_bytes)

        with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as tmp:
            wav_filename = tmp.name
            audio.export(wav_filename, format="wav")

        print(f"ğŸ§ æ”¶åˆ°éŸ³è¨Šï¼š{wav_filename}")

        segments, _ = model.transcribe(
            wav_filename,
            language="zh",
            beam_size=5,
            vad_filter=True,
        )

        new_sentences = []
        for seg in segments:
            sentence = seg.text.strip()
            new_sentences.append(sentence)
            last_sentences.append(sentence)

        final_text = new_sentences[-1] if new_sentences else "(ç„¡è¾¨è­˜åˆ°èªéŸ³)"

        if not os.path.exists("transcriptions"):
            os.makedirs("transcriptions")
        with open(os.path.join("transcriptions", "transcription.txt"), "w", encoding="utf-8") as f:
            f.write(final_text)

        emit("transcription", {
            "text": final_text,
            "download_url": "/download/transcription.txt"
        })

        os.remove(wav_filename)

    except Exception as e:
        print("âŒ èªéŸ³è¾¨è­˜éŒ¯èª¤ï¼š", e)
        emit("transcription", {"text": f"(éŒ¯èª¤ï¼š{str(e)})"})

@socketio.on("clear_transcription")
def clear_transcription():
    global last_sentences
    last_sentences = []
    emit("transcription", "")

# ğŸ“„ æä¾›ä¸‹è¼‰è¾¨è­˜çµæœ
@app.route("/download/<filename>")
def download_file(filename):
    return send_from_directory(directory="transcriptions", path=filename, as_attachment=True)

# âœ… å•Ÿå‹•ä¼ºæœå™¨
if __name__ == "__main__":
    socketio.run(app, host="0.0.0.0", port=8000)
