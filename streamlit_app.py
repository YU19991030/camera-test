import streamlit as st
import cv2
import av
import numpy as np
import requests
import base64
import tempfile
import sounddevice as sd
import soundfile as sf
from streamlit_webrtc import webrtc_streamer, VideoTransformerBase

# ğŸ”§ è«‹ä¿®æ”¹æˆä½ çš„å¾Œç«¯ FastAPI API ç¶²å€
API_BASE = "https://fe67-125-228-143-171.ngrok-free.app"

st.set_page_config(page_title="ğŸ“· å³æ™‚ OCR + ğŸ™ èªéŸ³è¾¨è­˜", layout="centered")
st.title("ğŸ“· å³æ™‚ PaddleOCR + ğŸ™ Whisper èªéŸ³è¾¨è­˜")

# ---------------------------
# ğŸ“¸ ç›¸æ©Ÿç•«é¢å³æ™‚æ“·å–è¾¨è­˜
# ---------------------------
st.header("ğŸ“¸ é¡é ­ç•«é¢å³æ™‚è¾¨è­˜")

class VideoProcessor(VideoTransformerBase):
    def __init__(self):
        self.latest_frame = None

    def transform(self, frame: av.VideoFrame) -> np.ndarray:
        image = frame.to_ndarray(format="bgr24")
        self.latest_frame = image.copy()
        return image

ctx = webrtc_streamer(
    key="ocr-cam",
    video_processor_factory=VideoProcessor,
    media_stream_constraints={"video": True, "audio": False},
    async_processing=True,
)

if st.button("ğŸ“¸ æ“·å–ä¸¦è¾¨è­˜ç•«é¢") and ctx.video_processor:
    frame = ctx.video_processor.latest_frame
    if frame is not None:
        _, buffer = cv2.imencode(".png", frame)
        base64_img = base64.b64encode(buffer).decode("utf-8")
        payload = {"image": f"data:image/png;base64,{base64_img}"}
        try:
            res = requests.post(f"{API_BASE}/ocr", json=payload)
            text = res.json().get("text", "")
            st.text_area("ğŸ“„ OCR è¾¨è­˜çµæœ", value=text, height=200)
        except Exception as e:
            st.error(f"âŒ OCR API éŒ¯èª¤ï¼š{e}")
    else:
        st.warning("âš ï¸ å°šæœªæ“·å–åˆ°ç•«é¢")

# ---------------------------
# ğŸ¤ éŒ„éŸ³èªéŸ³è¾¨è­˜ï¼ˆWhisperï¼‰
# ---------------------------
st.header("ğŸ¤ å³æ™‚èªéŸ³è¼¸å…¥è¾¨è­˜")

duration = st.slider("â± éŒ„éŸ³æ™‚é–“ï¼ˆç§’ï¼‰", 2, 10, 4)

if st.button("ğŸ™ é–‹å§‹éŒ„éŸ³"):
    with st.spinner("ğŸ™ éŒ„éŸ³ä¸­ï¼Œè«‹é–‹å§‹èªªè©±..."):
        fs = 16000
        audio = sd.rec(int(duration * fs), samplerate=fs, channels=1)
        sd.wait()

        with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as tmp:
            sf.write(tmp.name, audio, fs)
            tmp.seek(0)
            audio_bytes = tmp.read()

        st.audio(audio_bytes, format="audio/wav")

        with st.spinner("â³ è¾¨è­˜èªéŸ³ä¸­..."):
            try:
                res = requests.post(f"{API_BASE}/whisper", files={"file": ("audio.wav", audio_bytes, "audio/wav")})
                result = res.json().get("text", "")
                st.text_area("ğŸ“ èªéŸ³è¾¨è­˜çµæœ", value=result, height=200)
            except Exception as e:
                st.error(f"âŒ èªéŸ³ API éŒ¯èª¤ï¼š{e}")
 